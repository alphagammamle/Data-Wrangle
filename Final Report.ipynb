{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To get the following results, you should run the 'Data Wrangling SQL.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenStreetMap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenStreetMap (OSM) foundation is building free and editable map of the world, enabling the development of freely-reusable geospatial data. The data from OpenStreetMap is being used by many applications such as GoogleMaps, Foursquare and Craigslist. To look at the map, or download your area of interest, you can visit http://www.openstreetmap.org website. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, I chose Chicago, the Windy City in the US. This is the city where I got my undergrad degree.\n",
    "\n",
    "The original file is about 2 GB in size; I use a sample file about 50MB to perform my initial analysis on. Finally, I run it on the original file to create the CSV files for my database. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ET.iterparse (i.e. iterative parsing) is efficient here since the original file is too large for processing the whole thing.\n",
    "\n",
    "The main problem we encountered in the dataset is the street name inconsistencies. Below is the old name corrected with the better name. \n",
    "- Avenue (starting with capital letter)\n",
    "- Ave\n",
    "- Ave.\n",
    "- avenue (starting with small letter)\n",
    "\n",
    "To be able to process the data, we need to make these street types uniform. In case we are later searching for specific Avenue names, we can do a quick search on all street types that have the word 'Avenue' in them and we can make sure that we are not missing anything with abrreviations of Avenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auditing Postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postcodes are another inconsistent type of data that is entered into the map. The inconsistency is either in how they are represented (with the city abbreviation or without) or how long they are.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'get_postcode' function will take the 'tag' element as an input and return the elements for which the keys are equal to 'addr:postcode' \n",
    "\n",
    "The 'audit' function, like the one for street names, parses the XML file and iterates through node and way elements. It extracts the value attribute (i.e. the postcode) and add it to the 'dicti' dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Postcodes and Ways to Clean Them up\n",
    "The output shows that the postcodes are in these formats:\n",
    "- A 5-digit format (e.g. 12345)\n",
    "- A 5-digit format followed by more numbers after a hyphen (e.g. 12345-6789)\n",
    "\n",
    "To deal with the postcodes, I divide them into different categories:\n",
    "- First category include the ones:\n",
    "    - Where the length equals to 5 (e.g. 12345)\n",
    "    - Where the length is longer than 5, and they contain characters (like abbreviations of a city) \n",
    "- Second category include the ones:\n",
    "    - Where the length is longer than 5, and they are followed by a hyphen (e.g. 12345-6789)\n",
    "    \n",
    "- Third category include the ones:\n",
    "    - Where the length is longer than 5, but are not followed by any hyphen (e.g. 123456)\n",
    "    - Where the length is shorter than 5 (e.g. 1234, 515)\n",
    "    - Where the postcode equals to 'IL'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Data for the Database\n",
    "\n",
    "To load the data to the SQLite database, I need to transfer it from the XML file to CSV files. I create multiple CSV files, and later create the corresponding tables in my database based on them.\n",
    "\n",
    "The CSV files I want to have are:\n",
    "- Node\n",
    "- Node_tags\n",
    "- Way\n",
    "- Way_tags\n",
    "- Way_nodes\n",
    "\n",
    "Each of these CSV files contains different columns and stores data based on those columns. The columns used in the CSV files will be the table columns in the database. This is the schema:\n",
    "- NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "- NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "- WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "- WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "- WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get some information regarding the CSV files and the database I created.By importing 'hurry.filesize' I can translate the file sizes from bytes to KB or MB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import os\n",
    "from hurry.filesize import size \n",
    "dirpath = 'submission'\n",
    "\n",
    "\n",
    "files_list = []\n",
    "for path, dirs, files in os.walk(dirpath):\n",
    "    files_list.extend([(filename, size(os.path.getsize(os.path.join(path, filename)))) for filename in files])\n",
    "\n",
    "for filename, size in files_list:\n",
    "    print '{:.<40s}: {:5s}'.format(filename,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have audited and cleaned the data and transfered everything into table in my database, I can start running queries on it. The queries answer many questions such as:   \n",
    "- Number of nodes\n",
    "- Number of way\n",
    "- Number of unique users\n",
    "- Most contributing users\n",
    "- Number of users who contributed only once\n",
    "- Top 10 amenitie\n",
    "- Shops \n",
    "- Users who added amenities \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "sqlite_file = 'db.sqlite'\n",
    "con = sqlite3.connect(sqlite_file)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: \n",
      "8701756\n"
     ]
    }
   ],
   "source": [
    "def number_of_nodes():\n",
    "    output = cur.execute('SELECT COUNT(*) FROM nodes')\n",
    "    return output.fetchone()[0]\n",
    "\n",
    "print 'Number of nodes: \\n' , number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ways: \n",
      "1231106\n"
     ]
    }
   ],
   "source": [
    "def number_of_ways():\n",
    "    output = cur.execute('SELECT COUNT(*) FROM ways')\n",
    "    return output.fetchone()[0]\n",
    "\n",
    "print 'Number of ways: \\n' , number_of_ways()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of unique users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: \n",
      "2823\n"
     ]
    }
   ],
   "source": [
    "def number_of_unique_users():\n",
    "    output = cur.execute('SELECT COUNT(DISTINCT e.uid) FROM \\\n",
    "                         (SELECT uid FROM nodes UNION ALL SELECT uid FROM ways) e')\n",
    "    return output.fetchone()[0]\n",
    "\n",
    "print 'Number of unique users: \\n' , number_of_unique_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most contributing users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most contributing users: \n",
      "\n",
      "[(u'chicago-buildings', 5605968),\n",
      " (u'Umbugbene', 1091115),\n",
      " (u'woodpeck_fixbot', 219369),\n",
      " (u'alexrudd (NHD)', 204341),\n",
      " (u'g246020', 107386),\n",
      " (u'patester24', 105214),\n",
      " (u'mpinnau', 103495),\n",
      " (u'asdf1234', 101397),\n",
      " (u'Oak_Park_IL', 101251),\n",
      " (u'TIGERcnl', 93141)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_contributing_users():\n",
    "    \n",
    "    output = cur.execute('SELECT e.user, COUNT(*) as num FROM \\\n",
    "                         (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e \\\n",
    "                         GROUP BY e.user \\\n",
    "                         ORDER BY num DESC \\\n",
    "                         LIMIT 10 ')\n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Most contributing users: \\n'\n",
    "most_contributing_users()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of users who contributed once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users who have contributed once: \n",
      "636\n"
     ]
    }
   ],
   "source": [
    "def number_of_users_contributed_once():\n",
    "    \n",
    "    output = cur.execute('SELECT COUNT(*) FROM \\\n",
    "                             (SELECT e.user, COUNT(*) as num FROM \\\n",
    "                                 (SELECT user FROM nodes UNION ALL SELECT user FROM ways) e \\\n",
    "                                  GROUP BY e.user \\\n",
    "                                  HAVING num = 1) u')\n",
    "    \n",
    "    return output.fetchone()[0]\n",
    "                         \n",
    "print 'Number of users who have contributed once: \\n', number_of_users_contributed_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 amenities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top ten amenities: \n",
      "\n",
      "[(u'place_of_worship', 3038),\n",
      " (u'school', 1906),\n",
      " (u'restaurant', 1568),\n",
      " (u'fast_food', 899),\n",
      " (u'parking', 603),\n",
      " (u'cafe', 450),\n",
      " (u'bench', 426),\n",
      " (u'bicycle_parking', 414),\n",
      " (u'fuel', 388),\n",
      " (u'bicycle_rental', 361),\n",
      " (u'bank', 330),\n",
      " (u'drinking_water', 282),\n",
      " (u'bar', 257),\n",
      " (u'fountain', 229),\n",
      " (u'grave_yard', 216),\n",
      " (u'shelter', 204),\n",
      " (u'fire_station', 192),\n",
      " (u'toilets', 179),\n",
      " (u'pharmacy', 166),\n",
      " (u'pub', 162)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def top_ten_amenities_in_sf():\n",
    "    output = cur.execute('SELECT value, COUNT(*) as num FROM nodes_tags\\\n",
    "                            WHERE key=\"amenity\" \\\n",
    "                            GROUP BY value \\\n",
    "                            ORDER BY num DESC \\\n",
    "                            LIMIT 20' )\n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Top ten amenities: \\n'\n",
    "top_ten_amenities_in_sf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 cuisines: \n",
      "\n",
      "[(u'burger', 340),\n",
      " (u'mexican', 72),\n",
      " (u'chicken', 64),\n",
      " (u'pizza', 58),\n",
      " (u'american', 53),\n",
      " (u'coffee_shop', 36),\n",
      " (u'sandwich', 31),\n",
      " (u'italian', 30),\n",
      " (u'chinese', 17),\n",
      " (u'ice_cream', 16)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cuisines_in_sf():\n",
    "    output = cur.execute ('SELECT value, COUNT(*) as num FROM ways_tags \\\n",
    "                           WHERE key=\"cuisine\" \\\n",
    "                           GROUP BY value \\\n",
    "                           ORDER BY num DESC \\\n",
    "                           LIMIT 10')\n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Top 10 cuisines: \\n'\n",
    "cuisines_in_sf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different types of shops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users who added amenities to the map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different types of shops: \n",
      "\n",
      "[(u'place_of_worship', 3038),\n",
      " (u'school', 1906),\n",
      " (u'restaurant', 1568),\n",
      " (u'fast_food', 899),\n",
      " (u'parking', 603),\n",
      " (u'cafe', 450),\n",
      " (u'bench', 426),\n",
      " (u'bicycle_parking', 414),\n",
      " (u'fuel', 388),\n",
      " (u'bicycle_rental', 361),\n",
      " (u'bank', 330),\n",
      " (u'drinking_water', 282),\n",
      " (u'bar', 257),\n",
      " (u'fountain', 229),\n",
      " (u'grave_yard', 216),\n",
      " (u'shelter', 204),\n",
      " (u'fire_station', 192),\n",
      " (u'toilets', 179),\n",
      " (u'pharmacy', 166),\n",
      " (u'pub', 162)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shops_in_sf():\n",
    "    output = cur.execute('SELECT value, COUNT(*) as num FROM nodes_tags\\\n",
    "                            WHERE key=\"shop\" \\\n",
    "                            GROUP BY value \\\n",
    "                            ORDER BY num DESC' )\n",
    "    pprint.pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Different types of shops: \\n'\n",
    "top_ten_amenities_in_sf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users who added amenity to the map: \n",
      "\n",
      "[(u'DACGroup', u'Family Restaurant'),\n",
      " (u'DACGroup', u'Furniture Store'),\n",
      " (u'Dark Asteroid', u'Lombard Village Hall'),\n",
      " (u'DACGroup',\n",
      "  u'Portable Toilet Supplier;Trailer Rental Service;Construction Equipment Supplier;Fence Contractor'),\n",
      " (u'FrankRKryzak', u'arts_centre'),\n",
      " (u'Zol87', u'artwork'),\n",
      " (u'Tomasz11', u'atm'),\n",
      " (u'PhQ', u'baby_hatch'),\n",
      " (u'Tomasz11', u'bank'),\n",
      " (u'Umbugbene', u'banquet_hall')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def users_who_added_amenity():\n",
    "    output = cur.execute('SELECT DISTINCT(nodes.user), nodes_tags.value FROM \\\n",
    "                            nodes join nodes_tags \\\n",
    "                            on nodes.id=nodes_tags.id \\\n",
    "                            WHERE key=\"amenity\" \\\n",
    "                            GROUP BY value \\\n",
    "                            LIMIT 10' ) \n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Users who added amenity to the map: \\n'\n",
    "users_who_added_amenity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of postcodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of postcodes: \n",
      "\n",
      "[(u'60201', 9392),\n",
      " (u'60202', 7727),\n",
      " (u'60305', 1720),\n",
      " (u'60564', 1684),\n",
      " (u'60136', 1306)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def list_of_postcodes():\n",
    "    output = cur.execute('SELECT e.value, COUNT(*) as num FROM \\\n",
    "                            (SELECT value FROM nodes_tags WHERE key=\"postcode\"\\\n",
    "                             UNION ALL SELECT value FROM ways_tags WHERE key=\"postcode\") e \\\n",
    "                            GROUP BY e.value \\\n",
    "                            ORDER BY num DESC \\\n",
    "                            LIMIT 5' ) \n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'List of postcodes: \\n'\n",
    "list_of_postcodes()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amenities \n",
    "\n",
    "we checked to see what the amenities around this area are. Since the list was quite long, I limited it to the first 20 amenities with the highest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amenities around  \n",
      "\n",
      "[(u'place_of_worship', 3038),\n",
      " (u'school', 1906),\n",
      " (u'restaurant', 1568),\n",
      " (u'fast_food', 899),\n",
      " (u'parking', 603),\n",
      " (u'cafe', 450),\n",
      " (u'bench', 426),\n",
      " (u'bicycle_parking', 414),\n",
      " (u'fuel', 388),\n",
      " (u'bicycle_rental', 361),\n",
      " (u'bank', 330),\n",
      " (u'drinking_water', 282),\n",
      " (u'bar', 257),\n",
      " (u'fountain', 229),\n",
      " (u'grave_yard', 216),\n",
      " (u'shelter', 204),\n",
      " (u'fire_station', 192),\n",
      " (u'toilets', 179),\n",
      " (u'pharmacy', 166),\n",
      " (u'pub', 162)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def amenities_around_47906():\n",
    "    output = cur.execute('SELECT nodes_tags.value, COUNT(*) as num \\\n",
    "                          FROM nodes_tags \\\n",
    "                            JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE key=\"amenity\") AS amenities \\\n",
    "                            ON nodes_tags.id = amenities.id \\\n",
    "                            WHERE nodes_tags.key=\"amenity\"\\\n",
    "                            GROUP BY nodes_tags.value \\\n",
    "                            ORDER BY num DESC \\\n",
    "                            LIMIT 20' ) \n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Amenities around  \\n'\n",
    "amenities_around_47906()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popular Cafes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most popular cafes: \n",
      "\n",
      "[(u'Starbucks', 50),\n",
      " (u\"Dunkin' Donuts\", 13),\n",
      " (u'Starbucks Coffee', 10),\n",
      " (u\"Peet's Coffee & Tea\", 3),\n",
      " (u'Intelligentsia', 2),\n",
      " (u'Intelligentsia Coffee', 2),\n",
      " (u'Blue Max Coffee', 1),\n",
      " (u'Bow Truss Coffee Roasters', 1),\n",
      " (u'Brew Brew Coffee Lounge', 1),\n",
      " (u'Bridgeport Coffeehouse', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def most_popular_cafes():\n",
    "    output = cur.execute('SELECT nodes_tags.value, COUNT(*) as num \\\n",
    "                          FROM nodes_tags \\\n",
    "                            JOIN (SELECT DISTINCT(id) FROM nodes_tags WHERE value=\"coffee_shop\") AS cafes \\\n",
    "                            ON nodes_tags.id = cafes.id \\\n",
    "                            WHERE nodes_tags.key=\"name\"\\\n",
    "                            GROUP BY nodes_tags.value \\\n",
    "                            ORDER BY num DESC \\\n",
    "                            LIMIT 10' ) \n",
    "    pprint(output.fetchall())\n",
    "    return output.fetchall()\n",
    "\n",
    "print 'Most popular cafes: \\n'\n",
    "most_popular_cafes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "\n",
    "https://github.com/Dalaska/Udacity-Data-Wrangling-Clean-OpenStreetMap\n",
    "\n",
    "https://github.com/bestkao/data-wrangling-with-openstreetmap-and-mongodb\n",
    "\n",
    "https://discussions.udacity.com/t/display-files-and-their-sizes-in-directory/186741\n",
    "\n",
    "https://github.com/Nazaniiin/DataWrangling_OpenStreetMap\n",
    "\n",
    "https://github.com/alphagammamle/Udacity-Data-Analyst-Nanodegree/tree/master/P3-OpenStreetMap-Wrangling-with-SQL\n",
    "\n",
    "https://github.com/alphagammamle/OpenStreetMap-Toronto\n",
    "\n",
    "https://github.com/paul-reiners/udacity-data-wrangling-mongo-db/blob/master/docs/ProjectReport.md\n",
    "\n",
    "http://napitupulu-jon.appspot.com/posts/wrangling-openstreetmap.html\n",
    "\n",
    "http://puwenning.github.io/2016/02/10/P3-project-openstreetmap-data-case-study/\n",
    "\n",
    "http://fch808.github.io/Data%20Wrangling%20with%20MongoDB%20-%20Write-up.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
